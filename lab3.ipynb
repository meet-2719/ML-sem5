import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import math
import pandas as pd

#QUESTION 1a

data = pd.read_csv('ex2data1-logistic.csv')

data.head()
x1 = data['x1'].values
x1=x1.reshape((100,1))

x2 = data['x2'].values
x2=x2.reshape((100,1))

y = data['y'].values
y=y.reshape((100,1))


for i in range(0,90,1):
  if y[i]==0:
    plt.plot(x1[i],x2[i],'g+')
  else:
    plt.plot(x1[i],x2[i],'r+')

#question 2a


def gfunc (x):
  var = len(x)
  ans = np.zeros((var,1))
  for i in range(0,var,1):
      ans[i] = 1/(1+(math.exp(-x[i])))
  return ans

train_X1 = np.zeros((90,2))
train_y1 = np.zeros((90,1))
test_X1 = np.zeros((10,2))
test_y1 = np.zeros((10,1))
for i in range(0,90,1):
  train_X1[i][0] = x1[i]
  train_X1[i][1] = x2[i]
  train_y1[i] = y[i]
  
for i in range(90,100,1):
  test_X1[i-90] = x1[i]
  test_X1[i-90] = x2[i]
  test_y1[i-90] = y[i]

o = np.ones((train_X1.shape[0],1))
train_X = np.column_stack((o,train_X1 ))

o = np.ones((test_X1.shape[0],1))
test_X = np.column_stack((o, test_X1))
print(train_X.shape)
print(train_y1.shape)

print(test_X.shape)
print(test_y1.shape)



def gradientdescent (theta, alpha, iterations, X, y):
  m = X.shape[0]
  for i in range(iterations):
    v1 = y - gfunc(np.matmul(X,theta))
    v2 = np.matmul(X.transpose(),v1)
    theta = theta + (alpha/m)*v2
  return theta

theta = np.random.rand(3,1)
theta = gradientdescent(theta, 0.001,82000, train_X, train_y1)
print(theta)

res = np.zeros((10,1))
res = gfunc(np.matmul(test_X,theta))
print(res)

for i in range(0,10,1):
  if res[i]>=0.5:
    res[i]=1
  else:
    res[i]=0

var = 0;
for i in range(0,10,1):
  if res[i]==test_y1[i]:
     var=var+1
      
print(var)


for i in range(0,100,1):
  if y[i]==1:
    plt.plot(x1[i],x2[i],'r+')
  else:
    plt.plot(x1[i],x2[i],'g+')
plt.plot(x1,- (theta[0]/(theta[2]) + theta[1]*x1/theta[2] ))
plt.show()


data1 = pd.read_csv('ex2data2-logistic.csv')

data1.head()
x1 = data1['x1'].values
x1=x1.reshape((118,1))

x2 = data1['x2'].values
x2=x2.reshape((118,1))

y = data1['y'].values
y=y.reshape((118,1))


for i in range(0,106,1):
 
  if y[i]==0:
    plt.plot(x1[i],x2[i],'g+')
  else:
    plt.plot(x1[i],x2[i],'r+')


#Question 2b
def gfunc (x):
  var = len(x)
  ans = np.zeros((var,1))
  for i in range(0,var,1):
    ans[i] = 1/(1+math.exp(-x[i]))
  return ans

train_x1 = np.zeros((106,4))
train_y1 = np.zeros((106,1))
test_x1 = np.zeros((12,4))
test_y1 = np.zeros((12,1))

for i in range(0,106,1):
 train_x1[i][0] = x1[i]
 train_x1[i][1] = x2[i] 
 train_x1[i][2] = x1[i]**2
 train_x1[i][3] = x2[i]**2
 train_y1[i] = y[i]
  
for i in range(106,118,1):
  test_x1[i-106][0] = x1[i]
  test_x1[i-106][1] = x2[i]
  test_x1[i-106][2] = x1[i]**2
  test_x1[i-106][3] = x2[i]**2
  
  test_y1[i-106] = y[i]

o = np.ones((train_x1.shape[0],1))
train_X1 = np.column_stack((o, train_x1))

o = np.ones((test_x1.shape[0],1))
test_X1 = np.column_stack((o,test_x1))

print(train_X1.shape)
print(train_y1.shape)

print(test_X1.shape)
print(test_y1.shape)


def gradientdescent (theta, alpha, iterations, X, y):
  m = X.shape[0]
  for i in range(iterations):
    x1 = y - gfunc(np.matmul(X,theta))
    x2 = np.matmul(X.transpose(),x1)
    theta = theta + (alpha/m)*x2
  return theta

theta = np.random.rand(5,1)
theta = gradientdescent(theta, 0.01,82000, train_X1, train_y1)
print(theta)

res = np.zeros((12,1))
res = gfunc(np.matmul(test_X1,theta))
print(res)

for i in range(0,12,1):
  if res[i]>0.5:
    res[i]=1
  else:
    res[i]=0

var = 0;
for i in range(0,12,1):
  if res[i]==test_y1[i]:
     var=var+1
      
print(var)


  
for i in range(0,12,1):
  #print(y[i])
  if res[i]>0.5:
    plt.plot(x1[i],x2[i],'r+')
  else:
    plt.plot(x1[i],x2[i],'g+')


for i in range(0,100,1):
  if y[i]==1:
    plt.plot(x1[i],x2[i],'r+')
  else:
    plt.plot(x1[i],x2[i],'g+')
plt.plot(x1,- (theta[0]/(theta[2]) + theta[1]*x1/theta[2] ))
plt.show()
